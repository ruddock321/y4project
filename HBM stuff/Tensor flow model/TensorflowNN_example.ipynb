{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d0f2f8-c3f2-45b5-a954-69ec904ee6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import corner\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8b4cc9-1d5a-4064-a8e3-5442e06285d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts.PCANN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPCANN\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCANN\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mWMSE\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WMSE\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scripts.PCANN'"
     ]
    }
   ],
   "source": [
    "from scripts.PCANN import PCANN\n",
    "from scripts.WMSE import WMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7abce50-b0b3-4b9d-9828-9969d13855f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"smiley_stingray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e685880b-6c4e-4858-bc23-57ab206add8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emulatorpath = f\"./{run_name}/\"\n",
    "\n",
    "logfile = f\"log_{run_name}.json\"\n",
    "pcafile = f\"pca_{run_name}.json\"\n",
    "checkpointfile = f\"{run_name}_checkpoint.h5\"\n",
    "historyfile = f\"history_{run_name}.json\"\n",
    "\n",
    "with open(os.path.join(emulatorpath, logfile), \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "    gridpath = data[\"gridpath\"]\n",
    "    gridfile = data[\"gridfile\"]\n",
    "    grid = os.path.join(gridpath, gridfile)\n",
    "\n",
    "    seed = data[\"seed\"]\n",
    "    n_components = data[\"n_components\"]\n",
    "\n",
    "    batch_size_exp = data[\"batch_size_exp\"]\n",
    "    epochs = data[\"epochs\"]\n",
    "    test_size = data[\"test_size\"]\n",
    "    fractrain = data[\"fractrain\"]\n",
    "\n",
    "    inputs = data[\"inputs\"]\n",
    "    classical_outputs = data[\"classical_outputs\"]\n",
    "    nmin = data[\"nmin\"]\n",
    "    nmax = data[\"nmax\"]\n",
    "\n",
    "astero_outputs = [f\"nu_0_{i+1}\" for i in range(nmin - 1, nmax)]\n",
    "outputs = classical_outputs + astero_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889e7ce6-adb6-42e4-b9a3-cf6047a6198f",
   "metadata": {},
   "source": [
    "## A lot of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b6d6a9-f8e5-498e-91b8-3de8efd0b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pca_components(emulatorpath: str, pcafile: str) -> (np.array, np.array):\n",
    "    with open(os.path.join(emulatorpath, pcafile), \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "        pca_comps = np.array(data[\"pca_comps\"])\n",
    "        pca_mean = np.array(data[\"pca_mean\"])\n",
    "    return pca_comps, pca_mean\n",
    "\n",
    "\n",
    "def get_weights_and_biases(tf_model: Model) -> (list, list):\n",
    "    weights = list(map(jnp.asarray, tf_model.weights[::2]))\n",
    "    biases = list(map(jnp.asarray, tf_model.weights[1::2]))\n",
    "    return weights, biases\n",
    "\n",
    "\n",
    "def load_tf_model(\n",
    "    emulatorpath: str,\n",
    "    checkpointfile: str,\n",
    "    pcafile: str | None = None,\n",
    "    pca_comps: np.ndarray | None = None,\n",
    "    pca_mean: np.ndarray | None = None,\n",
    "    n: int = 25,\n",
    "):\n",
    "    if pca_comps is None or pca_mean is None:\n",
    "        assert pcafile is not None\n",
    "        pca_comps, pca_mean = load_pca_components(emulatorpath, pcafile)\n",
    "\n",
    "    custom_objects = {\n",
    "        \"PCANN\": PCANN(pca_comps, pca_mean),\n",
    "        \"WMSE\": WMSE(np.ones(n)),\n",
    "    }\n",
    "\n",
    "    tf_model = tf.keras.models.load_model(\n",
    "        os.path.join(emulatorpath, checkpointfile), custom_objects=custom_objects\n",
    "    )\n",
    "    return tf_model\n",
    "\n",
    "\n",
    "def load_emulator(run_name: str, emulatorpath: str, checkpointfile: str, pcafile: str):\n",
    "    pca_comps, pca_mean = load_pca_components(emulatorpath, pcafile)\n",
    "\n",
    "    tf_model = load_tf_model(\n",
    "        emulatorpath,\n",
    "        checkpointfile,\n",
    "        pca_comps=pca_comps,\n",
    "        pca_mean=pca_mean,\n",
    "    )\n",
    "    weights, biases = get_weights_and_biases(tf_model)\n",
    "\n",
    "    stem_map = [0, 1]\n",
    "    ctine_map = [-5, -3, -1]\n",
    "    atine_map = [-10, -9, -8, -7, -6, -4, -2]\n",
    "\n",
    "    emulator = (\n",
    "        weights,\n",
    "        biases,\n",
    "        stem_map,\n",
    "        ctine_map,\n",
    "        atine_map,\n",
    "        pca_comps,\n",
    "        pca_mean,\n",
    "    )\n",
    "    return emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1911968-4245-4fec-9adf-8b7bb5adccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logcols = [\n",
    "    \"initial_mass\",\n",
    "    \"alphaMLT\",\n",
    "    \"radius\",\n",
    "    \"luminosity\",\n",
    "    \"mass\",\n",
    "]\n",
    "logcols += [\"error_\" + col for col in logcols]\n",
    "\n",
    "\n",
    "def scale(\n",
    "    data: Union[pd.DataFrame, np.ndarray],\n",
    "    logcols: List[str] = logcols,\n",
    "    col_names: List[str] | None = None,\n",
    "    verbose: bool = False,\n",
    ") -> Union[pd.DataFrame, np.ndarray]:\n",
    "    if isinstance(data, np.ndarray):\n",
    "        if col_names is None:\n",
    "            raise ValueError(\"col_names must be provided when data is a NumPy array.\")\n",
    "        df_unnorm = pd.DataFrame(data, columns=col_names)\n",
    "    else:\n",
    "        df_unnorm = data\n",
    "\n",
    "    if col_names is None:\n",
    "        col_names = df_unnorm.columns\n",
    "        cols = df_unnorm.values.T\n",
    "    else:\n",
    "        cols = data.T\n",
    "\n",
    "    df_norm = df_unnorm.copy()\n",
    "    for col_name, col in zip(col_names, cols):\n",
    "        if col_name in logcols:\n",
    "            if verbose:\n",
    "                print(f\"{col_name} scaled with log10\")\n",
    "            df_norm[col_name] = np.log10(col)\n",
    "        elif col_name in [\"initial_y\", \"error_initial_y\"]:\n",
    "            if verbose:\n",
    "                print(f\"{col_name} scaled by multiply with 4 and log10\")\n",
    "            df_norm[col_name] = np.log10(col * 4)\n",
    "        elif col_name in [\"age\", \"error_age\"]:\n",
    "            if verbose:\n",
    "                print(f\"{col_name} scaled by dividing with 1000 and then log10\")\n",
    "            df_norm[col_name] = np.log10(col / 1000)\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"{col_name} not scaled\")\n",
    "\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return df_norm.values\n",
    "    return df_norm\n",
    "\n",
    "\n",
    "def descale(\n",
    "    data: Union[pd.DataFrame, np.ndarray],\n",
    "    logcols: List[str] = logcols,\n",
    "    col_names: List[str] | None = None,\n",
    "    verbose: bool = False,\n",
    ") -> Union[pd.DataFrame, np.ndarray]:\n",
    "    if isinstance(data, np.ndarray):\n",
    "        if col_names is None:\n",
    "            raise ValueError(\"col_names must be provided when data is a NumPy array.\")\n",
    "        df_norm = pd.DataFrame(data, columns=col_names)\n",
    "    else:\n",
    "        df_norm = data\n",
    "\n",
    "    if col_names is None:\n",
    "        col_names = df_norm.columns\n",
    "        cols = df_norm.values.T\n",
    "\n",
    "    df_unnorm = df_norm.copy()\n",
    "    for col_name, col in zip(col_names, cols):\n",
    "        if col_name in logcols:\n",
    "            if verbose:\n",
    "                print(f\"{col_name} descaled using inverse log10\")\n",
    "            df_unnorm[col_name] = 10 ** (col)\n",
    "        elif col_name == \"initial_y\":\n",
    "            if verbose:\n",
    "                print(f\"{col_name} descaled by inverse log10 and then divide by 4\")\n",
    "            df_unnorm[col_name] = (10 ** (col)) / 4\n",
    "        elif col_name == \"age\":\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"{col_name} descaled by inverse log10 and then multiply with 1000\"\n",
    "                )\n",
    "            df_unnorm[col_name] = (10 ** (col)) * 1000\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"{col_name} not descaled\")\n",
    "\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return df_unnorm.values\n",
    "    return df_unnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2fdad00-9157-4c63-bd50-ae706b30517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_emulator(\n",
    "    input_norm: np.ndarray,\n",
    "    emulator: Tuple[\n",
    "        np.ndarray, np.ndarray, list[int], list[int], list[int], np.ndarray, np.ndarray\n",
    "    ],\n",
    "    scale_dimensions: List[str] | None = None,\n",
    ") -> jax.Array:\n",
    "    stem = input_norm\n",
    "\n",
    "    (weights, biases, stem_map, ctine_map, atine_map, pca_comps, pca_mean) = emulator\n",
    "\n",
    "    for index in stem_map:\n",
    "        stem = jax.nn.elu(jnp.dot(stem, weights[index]) + biases[index])\n",
    "    xx = jnp.copy(stem)\n",
    "\n",
    "    for i, cindex in enumerate(ctine_map[:-1]):\n",
    "        if i == 0:\n",
    "            ctine = jax.nn.elu(jnp.dot(stem, weights[cindex]) + biases[cindex])\n",
    "        else:\n",
    "            ctine = jax.nn.elu(jnp.dot(ctine, weights[cindex]) + biases[cindex])\n",
    "    ctine_out = jnp.dot(ctine, weights[ctine_map[-1]]) + biases[ctine_map[-1]]\n",
    "\n",
    "    for i, aindex in enumerate(atine_map[:-1]):\n",
    "        if i == 0:\n",
    "            atine = jax.nn.elu(jnp.dot(stem, weights[aindex]) + biases[aindex])\n",
    "        else:\n",
    "            atine = jax.nn.elu(jnp.dot(atine, weights[aindex]) + biases[aindex])\n",
    "    atine_out = jnp.dot(atine, weights[atine_map[-1]]) + biases[atine_map[-1]]\n",
    "    atine_out = jnp.dot(atine_out, pca_comps) + pca_mean\n",
    "\n",
    "    out_norm = jnp.concatenate((ctine_out, atine_out), axis=-1)\n",
    "    return out_norm\n",
    "\n",
    "\n",
    "def call_emulator_with_df(\n",
    "    input_norm: pd.DataFrame,\n",
    "    emulator: Tuple[\n",
    "        np.ndarray, np.ndarray, list[int], list[int], list[int], np.ndarray, np.ndarray\n",
    "    ],\n",
    "    outputcolumns: list[str, ...],\n",
    "    verbose: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    np_input_norm = input_norm.to_numpy()\n",
    "    for i, row_norm in enumerate(np_input_norm):\n",
    "        out = call_emulator(\n",
    "            row_norm,\n",
    "            emulator,\n",
    "        )\n",
    "        out = out.reshape(-1, len(outputcolumns))\n",
    "        df_output_norm = pd.DataFrame(data=out, columns=outputcolumns, dtype=float)\n",
    "        df_output_unnorm = descale(df_output_norm, verbose=verbose)\n",
    "        if i == 0:\n",
    "            output_unnorm = df_output_unnorm\n",
    "        else:\n",
    "            output_unnorm = np.vstack([output_unnorm, df_output_unnorm])\n",
    "    df_output_unnorm = pd.DataFrame(data=output_unnorm, columns=outputcolumns)\n",
    "    return df_output_unnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45ec617-5483-4563-999f-5f66f2dbb9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_input(\n",
    "    test_star_linear: dict | None = None,\n",
    "    df: pd.DataFrame | None = None,\n",
    "    idx: int | None = None,\n",
    "    inputs: list[str, ...] = inputs,\n",
    ") -> pd.DataFrame:\n",
    "    assert (test_star_linear is not None) | ((df is not None) & (idx is not None))\n",
    "    if test_star_linear is not None:\n",
    "        # This is a manual input using a dict to make a star\n",
    "        df_test_star_linear = pd.DataFrame(data=test_star_linear)\n",
    "        df_test_star = scale(df_test_star_linear)\n",
    "        assert df_test_star_linear.equals(descale(df_test_star))\n",
    "\n",
    "        test_input = np.array([df_test_star.values.tolist()[0]])\n",
    "    else:\n",
    "        # This looks up df[idx] and uses this as test input\n",
    "        test_input = np.array([df.loc[idx][inputs].values])\n",
    "    return test_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5affc53-ffbf-4d10-a349-477f29d41208",
   "metadata": {},
   "source": [
    "## Make a simulated star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db9a2b2c-5e3d-47fa-8b74-4a3c1233c185",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_star_linear = {\n",
    "    \"initial_mass\": np.asarray(\n",
    "        [\n",
    "            1.0,\n",
    "            0.9,\n",
    "        ]\n",
    "    ),\n",
    "    \"MeH\": [\n",
    "        0.0,\n",
    "        -0.1,\n",
    "    ],\n",
    "    \"alphaFe\": [\n",
    "        0.0,\n",
    "        0.2,\n",
    "    ],\n",
    "    \"initial_y\": [\n",
    "        0.26,\n",
    "        0.26,\n",
    "    ],\n",
    "    \"alphaMLT\": [\n",
    "        2.0,\n",
    "        2.0,\n",
    "    ],\n",
    "    \"eta\": [\n",
    "        0.01,\n",
    "        0.01,\n",
    "    ],\n",
    "    \"normalised_age\": [\n",
    "        0,\n",
    "        0.2,\n",
    "    ],\n",
    "}\n",
    "\n",
    "test_input_norm = scale(pd.DataFrame.from_dict(test_star_linear))\n",
    "# get_test_input(test_star_linear=test_star_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "770f831a-ef9b-4075-bf17-9353181dcbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_mass</th>\n",
       "      <th>MeH</th>\n",
       "      <th>alphaFe</th>\n",
       "      <th>initial_y</th>\n",
       "      <th>alphaMLT</th>\n",
       "      <th>eta</th>\n",
       "      <th>normalised_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.045757</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.017033</td>\n",
       "      <td>0.30103</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initial_mass  MeH  alphaFe  initial_y  alphaMLT   eta  normalised_age\n",
       "0      0.000000  0.0      0.0   0.017033   0.30103  0.01             0.0\n",
       "1     -0.045757 -0.1      0.2   0.017033   0.30103  0.01             0.2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae2d5028-e601-493b-9542-3637f01147f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "tf_model = load_tf_model(\n",
    "    emulatorpath=emulatorpath,\n",
    "    checkpointfile=checkpointfile,\n",
    "    pcafile=pcafile,\n",
    "    n=nmax - nmin,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cba68fb-bd47-4829-8a04-d677c05f0bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n"
     ]
    }
   ],
   "source": [
    "modelprediction = tf_model.predict(test_input_norm)\n",
    "preds_norm = tf.concat(modelprediction, 1)\n",
    "df_preds_norm = pd.DataFrame(preds_norm, columns=outputs, dtype=float)\n",
    "df_preds = descale(df_preds_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ed20119-1065-4273-86f4-ca08c20de03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius</th>\n",
       "      <th>luminosity</th>\n",
       "      <th>mass</th>\n",
       "      <th>age</th>\n",
       "      <th>nu_0_1</th>\n",
       "      <th>nu_0_2</th>\n",
       "      <th>nu_0_3</th>\n",
       "      <th>nu_0_4</th>\n",
       "      <th>nu_0_5</th>\n",
       "      <th>nu_0_6</th>\n",
       "      <th>...</th>\n",
       "      <th>nu_0_12</th>\n",
       "      <th>nu_0_13</th>\n",
       "      <th>nu_0_14</th>\n",
       "      <th>nu_0_15</th>\n",
       "      <th>nu_0_16</th>\n",
       "      <th>nu_0_17</th>\n",
       "      <th>nu_0_18</th>\n",
       "      <th>nu_0_19</th>\n",
       "      <th>nu_0_20</th>\n",
       "      <th>nu_0_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.260889</td>\n",
       "      <td>2.978988</td>\n",
       "      <td>0.999034</td>\n",
       "      <td>12282.851520</td>\n",
       "      <td>62.477612</td>\n",
       "      <td>114.506554</td>\n",
       "      <td>162.430389</td>\n",
       "      <td>208.015564</td>\n",
       "      <td>252.467346</td>\n",
       "      <td>295.544159</td>\n",
       "      <td>...</td>\n",
       "      <td>532.782654</td>\n",
       "      <td>572.258728</td>\n",
       "      <td>612.109375</td>\n",
       "      <td>651.628601</td>\n",
       "      <td>692.060242</td>\n",
       "      <td>732.139465</td>\n",
       "      <td>772.875977</td>\n",
       "      <td>813.355042</td>\n",
       "      <td>854.031616</td>\n",
       "      <td>894.859070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.546391</td>\n",
       "      <td>3.667733</td>\n",
       "      <td>0.899824</td>\n",
       "      <td>15569.359825</td>\n",
       "      <td>49.285847</td>\n",
       "      <td>90.772896</td>\n",
       "      <td>128.693268</td>\n",
       "      <td>164.908096</td>\n",
       "      <td>200.138870</td>\n",
       "      <td>233.358337</td>\n",
       "      <td>...</td>\n",
       "      <td>419.850830</td>\n",
       "      <td>451.191528</td>\n",
       "      <td>482.874695</td>\n",
       "      <td>514.497253</td>\n",
       "      <td>546.805176</td>\n",
       "      <td>578.810303</td>\n",
       "      <td>611.289490</td>\n",
       "      <td>643.438843</td>\n",
       "      <td>675.483032</td>\n",
       "      <td>707.394043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius  luminosity      mass           age     nu_0_1      nu_0_2  \\\n",
       "0  2.260889    2.978988  0.999034  12282.851520  62.477612  114.506554   \n",
       "1  2.546391    3.667733  0.899824  15569.359825  49.285847   90.772896   \n",
       "\n",
       "       nu_0_3      nu_0_4      nu_0_5      nu_0_6  ...     nu_0_12  \\\n",
       "0  162.430389  208.015564  252.467346  295.544159  ...  532.782654   \n",
       "1  128.693268  164.908096  200.138870  233.358337  ...  419.850830   \n",
       "\n",
       "      nu_0_13     nu_0_14     nu_0_15     nu_0_16     nu_0_17     nu_0_18  \\\n",
       "0  572.258728  612.109375  651.628601  692.060242  732.139465  772.875977   \n",
       "1  451.191528  482.874695  514.497253  546.805176  578.810303  611.289490   \n",
       "\n",
       "      nu_0_19     nu_0_20     nu_0_21  \n",
       "0  813.355042  854.031616  894.859070  \n",
       "1  643.438843  675.483032  707.394043  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022c344-bf94-4bf3-be8f-5b1c80756667",
   "metadata": {},
   "source": [
    "## How I use it in my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acb9c4-4e54-4f99-a46c-2d005bcba59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(\n",
    "#     emulator,\n",
    "#     error_obs: dict | pd.DataFrame,\n",
    "#     obs: dict | pd.DataFrame | None = None,\n",
    "#     modelparams: dict | None = None,\n",
    "#     modelhyperparams: dict | None = None,\n",
    "#     fillvalue: float | None = None,\n",
    "# ):\n",
    "#     if fillvalue is None:\n",
    "#         fillvalue = constants.fillvalue\n",
    "\n",
    "#     # Do stuff with priors\n",
    "\n",
    "#     # Emulate observables\n",
    "#     input_norm = jnp.stack(\n",
    "#         [\n",
    "#             jnp.log10(initial_mass),\n",
    "#             initial_MeH,\n",
    "#             alphaFe,\n",
    "#             jnp.log10(initial_y * 4),\n",
    "#             jnp.log10(alphaMLT),\n",
    "#             eta,\n",
    "#             normalised_age,\n",
    "#         ],\n",
    "#         axis=-1,\n",
    "#     )\n",
    "\n",
    "#     output_norm = call_emulator(input_norm=input_norm, emulator=emulator)\n",
    "\n",
    "#     # Unpack and descale\n",
    "#     radius = numpyro.deterministic(\"radius\", 10 ** output_norm[:, 0])\n",
    "#     luminosity = numpyro.deterministic(\"luminosity\", 10 ** output_norm[:, 1])\n",
    "#     teff = numpyro.deterministic(\n",
    "#         \"teff\", constants.teff_sun * (radius ** (-2) * luminosity) ** (0.25)\n",
    "#     )\n",
    "#     mass = numpyro.deterministic(\"mass\", 10 ** output_norm[:, 2])\n",
    "#     age = numpyro.deterministic(\"age\", (10 ** output_norm[:, 3]) * 1000)\n",
    "\n",
    "#     # Compute numax for the sole purpose of being a scale in the surface correction\n",
    "#     dnu = jnp.median(jnp.diff(output_norm[:, len(classical_outputs) :]))  # len(classical_outputs) = 4\n",
    "#     numax = (dnu / 0.263) ** (1 / 0.772)  # Stello et al\n",
    "\n",
    "#     if obs is not None:\n",
    "#         numpyro.sample(\n",
    "#             f\"observed_teff\",\n",
    "#             dist.StudentT(5, teff, error_obs[\"teff\"]),\n",
    "#             obs=obs[\"teff\"],\n",
    "#         )\n",
    "#         numpyro.sample(\n",
    "#             f\"observed_luminosity\",\n",
    "#             dist.StudentT(5, luminosity, error_obs[\"luminosity\"]),\n",
    "#             obs=obs[\"luminosity\"],\n",
    "#         )\n",
    "\n",
    "#         # etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
